<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>blace.ai: Getting Started</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">blace.ai
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('index.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Getting Started </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_welcome"></a> For an easy start simply visit the <a class="el" href="getting_started.html#quickstart_demo">Quickstart</a> or <a class="el" href="hub_quickstart.html#quickstart_hub">Quickstart from Hub</a> page.</p>
<h1><a class="anchor" id="autotoc_md1"></a>
Installation / Integration into CMake projects</h1>
<p>Integrating blace.ai into your project is super simple. You need to:</p><ol type="1">
<li>Download the blace.ai package from <a href="https://github.com/blace-ai/blace-ai/releases">github.com/blace-ai/blace-ai/releases</a> and place it in your project.</li>
<li>Include blace.ai cmake configuration in your CMakeLists.txt: <br  />
 <code>include("../cmake/FindBlace.cmake")</code></li>
<li>Link your target to blace.ai: <br  />
 <code>target_link_libraries(&lt;your_target&gt; PRIVATE 3rdparty::BlaceAI)</code></li>
<li>Add a post-build phase to copy all blace.ai libraries next to your executable: <div class="fragment"><div class="line">foreach(DLL_FILE ${BLACE_AI_COPY_LIBS})</div>
<div class="line">    add_custom_command(TARGET &lt;your_target&gt; POST_BUILD COMMAND ${CMAKE_COMMAND} -E </div>
<div class="line">        copy &quot;${DLL_FILE}&quot; $&lt;TARGET_FILE_DIR:your_target&gt;</div>
<div class="line">    )</div>
<div class="line">endforeach()</div>
</div><!-- fragment --></li>
</ol>
<p><b>Important:</b> This setup is the same on all operating systems so you can start developing e.g. on Windows and later deploy from Ubuntu by simply downloading a different (the Ubuntu) version of the package there. The folder structure is always the same. The same goes for coding: The same code works across all operating systems.</p>
<h1><a class="anchor" id="autotoc_md2"></a>
Usage</h1>
<p>Add </p><div class="fragment"><div class="line"><span class="preprocessor">#include &quot;blace_ai.h&quot;</span></div>
</div><!-- fragment --><p> at the top of your source file. This will make all headers available.</p>
<p>blace.ai makes use of a so-call computation graph to execute all commands. This allows for implicit caching of reusable results (like model inferences with exact same arguments) across runs. Therefore usage is split into two phases, graph construction and graph execution.</p>
<h2><a class="anchor" id="autotoc_md3"></a>
Model Registering / Execution</h2>
<p>All models that are coming from the <a href="https://blace.ai/hub">model hub</a> or our Model Wizard consist of two artifacts: The .h model header and the .bin payload(s).</p>
<p>In order to run the model you need to</p><ol type="1">
<li>Include the header <div class="fragment"><div class="line"><span class="preprocessor">#include &quot;depth_anything_v2_v8_small_v3_ALL_export_version_v17.h&quot;</span></div>
</div><!-- fragment --> This will provide you with <div class="fragment"><div class="line"><span class="keyword">const</span> std::vector&lt;char&gt; depth_anything_v2_v8_small_v3_ALL_export_version_v17 <span class="comment">// the encoded model metadata</span></div>
<div class="line"><span class="keyword">const</span> std::string depth_anything_v2_v8_small_v3_ALL_export_version_v17_IDENT <span class="comment">// model identification string</span></div>
<div class="line"><span class="keyword">inline</span> blace::ops::OpP depth_anything_v2_v8_small_v3_ALL_export_version_v17_run(..., <span class="keywordtype">int</span> return_index, <a class="code hl_class" href="classblace_1_1ml__core_1_1InferenceArgsCollection.html">blace::ml_core::InferenceArgsCollection</a> inference_args, std::string payload_folder) <span class="comment">// a method with all arguments exposed (only for models coming from the hub)</span></div>
<div class="ttc" id="aclassblace_1_1ml__core_1_1InferenceArgsCollection_html"><div class="ttname"><a href="classblace_1_1ml__core_1_1InferenceArgsCollection.html">blace::ml_core::InferenceArgsCollection</a></div><div class="ttdef"><b>Definition</b> types.h:486</div></div>
</div><!-- fragment --></li>
<li>When you later construct a inference operation you pass in the encoded model metadata. This will automatically register the model in the library. <div class="fragment"><div class="line"><span class="keyword">auto</span> infer_op = CONSTRUCT_OP(ops::InferenceOp(</div>
<div class="line">    depth_anything_v2_v8_small_v3_ALL_export_version_v17, {interpolated},</div>
<div class="line">    infer_args, 0, util::getPathToExe().string()));</div>
</div><!-- fragment --> The last argument is the path where the .bin model payloads are searched during execution. In this case we expect it next to the executable.</li>
</ol>
<h2><a class="anchor" id="autotoc_md4"></a>
Graph building</h2>
<p>First, you construct the computation graph (a DAG). Refer to <a class="el" href="public__ops_8h_source.html">public_ops.h</a> to see an overview of all available operators (we have a limited set during beta but will roll out the rest of the operators soon).</p>
<p>Such a construction could look like (taken from the Gemma demo project): </p><div class="fragment"><div class="line"><span class="keyword">auto</span> text_t = CONSTRUCT_OP_GET(<a class="code hl_class" href="classblace_1_1ops_1_1FromTextOp.html">blace::ops::FromTextOp</a>(str));</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> output_len = CONSTRUCT_OP_GET(<a class="code hl_class" href="classblace_1_1ops_1_1FromIntOp.html">blace::ops::FromIntOp</a>(200));</div>
<div class="line"><span class="keyword">auto</span> temperature = CONSTRUCT_OP_GET(<a class="code hl_class" href="classblace_1_1ops_1_1FromFloatOp.html">blace::ops::FromFloatOp</a>(0.));</div>
<div class="line"><span class="keyword">auto</span> top_p = CONSTRUCT_OP_GET(<a class="code hl_class" href="classblace_1_1ops_1_1FromFloatOp.html">blace::ops::FromFloatOp</a>(0.9));</div>
<div class="line"><span class="keyword">auto</span> top_k = CONSTRUCT_OP_GET(<a class="code hl_class" href="classblace_1_1ops_1_1FromIntOp.html">blace::ops::FromIntOp</a>(50));</div>
<div class="line"> </div>
<div class="line"><a class="code hl_class" href="classblace_1_1ml__core_1_1InferenceArgsCollection.html">blace::ml_core::InferenceArgsCollection</a> infer_args;</div>
<div class="line"><span class="comment">// get available accelerator (cuda or metal device)</span></div>
<div class="line">infer_args.<a class="code hl_variable" href="classblace_1_1ml__core_1_1InferenceArgsCollection.html#a837d019366e38fed2b21fd4c8a47e646">inference_args</a>.backend = {blace::ml_core::TORCHSCRIPT_CUDA_FP16};</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> infer_op = CONSTRUCT_OP_GET(<a class="code hl_class" href="classblace_1_1ops_1_1InferenceOp.html">blace::ops::InferenceOp</a>(gemma_v1_default_v1_ALL_export_version_v10,</div>
<div class="line">            {text_t, output_len, temperature, top_p, top_k}, infer_args, 0));</div>
<div class="ttc" id="aclassblace_1_1ml__core_1_1InferenceArgsCollection_html_a837d019366e38fed2b21fd4c8a47e646"><div class="ttname"><a href="classblace_1_1ml__core_1_1InferenceArgsCollection.html#a837d019366e38fed2b21fd4c8a47e646">blace::ml_core::InferenceArgsCollection::inference_args</a></div><div class="ttdeci">ModelInferenceArgs inference_args</div><div class="ttdef"><b>Definition</b> types.h:491</div></div>
<div class="ttc" id="aclassblace_1_1ops_1_1FromFloatOp_html"><div class="ttname"><a href="classblace_1_1ops_1_1FromFloatOp.html">blace::ops::FromFloatOp</a></div><div class="ttdef"><b>Definition</b> public_ops.h:137</div></div>
<div class="ttc" id="aclassblace_1_1ops_1_1FromIntOp_html"><div class="ttname"><a href="classblace_1_1ops_1_1FromIntOp.html">blace::ops::FromIntOp</a></div><div class="ttdef"><b>Definition</b> public_ops.h:98</div></div>
<div class="ttc" id="aclassblace_1_1ops_1_1FromTextOp_html"><div class="ttname"><a href="classblace_1_1ops_1_1FromTextOp.html">blace::ops::FromTextOp</a></div><div class="ttdef"><b>Definition</b> public_ops.h:85</div></div>
<div class="ttc" id="aclassblace_1_1ops_1_1InferenceOp_html"><div class="ttname"><a href="classblace_1_1ops_1_1InferenceOp.html">blace::ops::InferenceOp</a></div><div class="ttdef"><b>Definition</b> public_ops.h:150</div></div>
</div><!-- fragment --><p>Note how five input nodes are constructed and fed into the <code>infer_op</code> construction. All relevant model inference arguments are hold by a <a class="el" href="classblace_1_1ml__core_1_1InferenceArgsCollection.html">blace::ml_core::InferenceArgsCollection</a> object. <b>Important:</b> At this point, no model is loaded or executed. We simply define the execution structure.</p>
<h2><a class="anchor" id="autotoc_md5"></a>
Inference Backends</h2>
<p>In blace.ai a backend is defined as a combination of a framework (like torchscript or onnx), an provider (CPU, CUDA, DirectML etc.) and a precision and has the format <code>&lt;framework&gt;_&lt;provider&gt;_&lt;precision&gt;</code>, e.g. <code>TORCHSCRIPT_CUDA_FP16</code>. All supported backends are defined in <a class="el" href="types_8h.html#a239855ac72f96bdb44cbffeae07b40f9">blace::ml_core::Backend</a>. When constructing an inference operator you pass a list of <a class="el" href="types_8h.html#a239855ac72f96bdb44cbffeae07b40f9">blace::ml_core::Backend</a> to the <a class="el" href="structblace_1_1ml__core_1_1ModelInferenceArgs.html">blace::ml_core::ModelInferenceArgs</a>. Upon execution blace.ai will go through the list and run the model on the first backend that is supported by the model and the host. Please see the provided demo for an example.</p>
<h2><a class="anchor" id="autotoc_md6"></a>
Graph Execution</h2>
<p>Now that we have constructed the graph we can execute it. We do so by constructing a <a class="el" href="classblace_1_1computation__graph_1_1GraphEvaluator.html">blace::computation_graph::GraphEvaluator</a> from the last node (whichs result we want to get) and running the evaluation: </p><div class="fragment"><div class="line"><a class="code hl_class" href="classblace_1_1computation__graph_1_1GraphEvaluator.html">blace::computation_graph::GraphEvaluator</a> evaluator(infer_op);</div>
<div class="line"><span class="keyword">auto</span> answer = evaluator.evaluateToString().value();</div>
<div class="line">std::cout &lt;&lt; <span class="stringliteral">&quot;Answer: &quot;</span> &lt;&lt; answer &lt;&lt; std::endl;</div>
<div class="ttc" id="aclassblace_1_1computation__graph_1_1GraphEvaluator_html"><div class="ttname"><a href="classblace_1_1computation__graph_1_1GraphEvaluator.html">blace::computation_graph::GraphEvaluator</a></div><div class="ttdef"><b>Definition</b> graph_evaluator.h:34</div></div>
</div><!-- fragment --><p>If the evaluation fails answer will hold a <code>std::nullopt</code>.</p>
<h2><a class="anchor" id="autotoc_md7"></a>
Error Handling</h2>
<p>Our library will never throw exceptions at you. Instead, all calls to methods through the api wrap the result in a <code>std::optional</code> which will hold a <code>std::nullopt</code> in case of failure. The console will print the error message in this case.</p>
<h1><a class="anchor" id="autotoc_md8"></a>
Using models from the hub</h1>
<p>Our <a href="https://blace.ai/hub">model hub</a> contains a growing list of compatible models which you can integrate in your application with a few lines of code. Check <a class="el" href="hub_quickstart.html#quickstart_hub">Quickstart from Hub</a> to learn how to run the provided demo projects. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
